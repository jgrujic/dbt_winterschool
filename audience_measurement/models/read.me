## To make the run incremental:

## look at commit "cleaned up increment tables, added tests"

## Bellow is the instruction how to run that version:

## Most important it to add this in the beginning of the file:
{{
        config(
                materialized='incremental', unique_key='sequence'
        )
}}

## This code is meant to run for event happened on a certain date
## You can run it multiple times per day and it will update the information
## accordingly and override the information in the table for that whole day, 
## without duplicating the rows
## However, it is not meant to handle the edge cases well 
## For example the session started on one day and finishing the next

## To run the model on real data:

dbt run --vars '{key: value, date: 2021-02-10}'
dbt run --profiles-dir /workspace/dbt --project-dir /workspace/dbt/dbt_training --target "dbtjelena"  --vars '{"date": 20211203, "num_days": 1}'

in datafy:  make run target=dbtjelena vars='{key: value, date: 2021-12-03}'
make run vars='{"date": 20211203, "num_days": 1}'


On Datafy:
make run vars='{key: value, date: 2021-02-10}'

## To run it on synthetic data:
## edit files lore_clean.sql and epg_clean.sql 
## and change the source to *_multidays 
## To run:

dbt run --vars '{key: value, date: 2017-07-03}'
dbt run --vars '{key: value, date: 2017-07-04}'
dbt run --vars '{key: value, date: 2017-07-05}'

## All the data will be added to the same tables
## To delete them and start over write in snowflake:

drop table lore_clean;
drop table epg_clean;
drop table session;
drop table enriched_session;
drop table agg_per_program;
drop table agg_per_digiboxid;

### Note

### if you want to run the code in real time
### Update only the new information, you should rewrite the code
### to use this:
{{
    config(
        materialized='incremental'
    )
}}

select
   .
   .
   .
{% if is_incremental() %}
    where timestamp >= (select max(timestamp) from {{this}})

{% endif %}

### Caution: It might be tricky to update te "end" time in "session" this
### way.
